# CNN 笔记
## MNIST数据集
6万张训练图片，1万测试图片 28*28
## 代码解析
```python
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)#下载数据集
```
下载数据集      
```python
tf.placeholder(dtype, shape=None, name=None)
```
此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值    
dtype：数据类型。常用的是tf.float32,tf.float64等数值类型    
shape：数据形状。默认是None，就是一维值，也可以是多维，比如[2,3], [None, 3]表示列是3，行不定    
name：名称。

```python
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
```
生成标准正态分布的
shape: 一维的张量，也是输出的张量。     
mean: 正态分布的均值。    
stddev: 正态分布的标准差。    
dtype: 输出的类型。    
seed: 一个整数，当设置之后，每次生成的随机数都一样。   
name: 操作的名字。   

```python
tf.nn.conv2d (input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
```
input :输入的要做卷积的图片，要求为一个张量   
shape为 [ batch, in_height, in_weight, in_channel ]   
batch为图片的数量，in_height 为图片高度，in_weight 为图片宽度，in_channel 为图片的通道数，灰度图该值为1，彩色图为3。（也可以用其它值，但是具体含义不是很理解）   
filter：卷积核，要求也是一个张量  
shape为 [ filter_height, filter_weight, in_channel, out_channels ]     
filter_height 为卷积核高度，filter_weight 为卷积核宽度，in_channel 是图像通道数 ，和 input 的 in_channel 要保持一致，out_channel 是卷积核数量    
strides：卷积时在图像每一维的步长，这是一个一维的向量，[ 1, strides, strides, 1]，第一位和最后一位固定必须是1      
padding： string类型，值为“SAME” 和 “VALID”，表示的是卷积的形式，是否考虑边界。"SAME"是考虑边界，不足的时候用0去填充周围，"VALID"则不考虑      
use_cudnn_on_gpu： bool类型，是否使用cudnn加速，默认为true

```python
tf.nn.max_pool(value, ksize, strides, padding, name=None)
```

value：需要池化的输入，一般池化层接在卷积层后面，所以输入通常是feature map，依然是[batch, height, width, channels]这样的shape     
ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]，因为我们不想在batch和channels上做池化，所以这两个维度设为了1     
strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]    
padding：和卷积类似，可以取'VALID' 或者'SAME'    

```python
tf.reshape(tensor,shape,name=None)
```
如果不知道维度用-1代替

```python
W_conv2=weight_variable([5,5,6,12])
```
前两位为卷积核大小，第三位为输入个数，第四位为输出个数

keep_prob: A scalar Tensor with the same type as x. The probability that each element is kept.
意思是每个元素被保留的概率，那么 keep_prob:1就是所有元素全部保留的意思。
一般在大量数据训练时，为了防止过拟合，添加Dropout层，设置一个0~1之间的小数，
